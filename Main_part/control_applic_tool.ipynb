{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "collections.Iterable = collections.abc.Iterable\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import sys\n",
    "import urx\n",
    "import numpy as np\n",
    "import math\n",
    "import threading\n",
    "import io\n",
    "import socket\n",
    "import struct\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy\n",
    "import pupil_apriltags as apriltag\n",
    "import time\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import transforms3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = False\n",
    "tag_pose = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_receiver(connection,detector,camera_params,tag_size,robot,goal,home,accuracy):\n",
    "    global tag,tag_pose,threads_active\n",
    "    print(\"coord_reciever thread started\")\n",
    "    \n",
    "    while threads_active:\n",
    "        image_len = struct.unpack(\n",
    "            '<L', connection.read(struct.calcsize('<L')))[0]\n",
    "        # print('I am here')\n",
    "        if not image_len:\n",
    "            break\n",
    "        image_stream = io.BytesIO()\n",
    "        image_stream.write(connection.read(image_len))\n",
    "        image_stream.seek(0)\n",
    "        image = Image.open(image_stream)\n",
    "        opencvImage = cv2.cvtColor(numpy.array(image), cv2.COLOR_RGB2BGR)\n",
    "        gray = cv2.cvtColor(opencvImage, cv2.COLOR_BGR2GRAY)\n",
    "        result = detector.detect(\n",
    "            gray, estimate_tag_pose=True, camera_params=camera_params, tag_size=tag_size)\n",
    "\n",
    "        if result:\n",
    "            tag = True\n",
    "            tag_pose = result[0].pose_t\n",
    "            print('coords=',tag_pose)\n",
    "        else:\n",
    "            tag=False\n",
    "            tag_pose = []\n",
    "        cv2.imshow('Image', opencvImage)\n",
    "\n",
    "        current_rob_pose = robot.getl()\n",
    "        diff = -np.array(current_rob_pose[:3])+np.array(goal[:3])\n",
    "        v = diff/np.max(np.abs(diff))*0.01\n",
    "        robot.speedl((v[0],v[1],v[2],0,0,0),0.05,1)\n",
    "        distance = np.linalg.norm(diff)\n",
    "\n",
    "        if distance <=accuracy:\n",
    "            robot.speedl((0,0,0,0,0,0),0.05,1)\n",
    "            threads_active = False\n",
    "\n",
    "        if tag and np.linalg.norm(tag_pose) < 0.2:\n",
    "            print('COLLISION')\n",
    "            robot.speedl((0,0,0,0,0,0),0.05,1)\n",
    "            robot.movel((home[0],home[1],home[2],home[3],home[4],home[5]),0.01,0.01)\n",
    "            threads_active = False\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('q'):\n",
    "            threads_active = False\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manip_control(robot,goal,home,accuracy, conn):\n",
    "    global threads_active\n",
    "    print(\"manip_control process started\")\n",
    "    while threads_active:\n",
    "        current_rob_pose = robot.getl()\n",
    "        diff = -np.array(current_rob_pose[:3])+np.array(goal[:3])\n",
    "        v = diff/np.max(np.abs(diff))*0.01\n",
    "        robot.speedl((v[0],v[1],v[2],0,0,0),0.05,1)\n",
    "        distance = np.linalg.norm(diff)\n",
    "\n",
    "        if distance <=accuracy:\n",
    "            robot.speedl((0,0,0,0,0,0),0.05,1)\n",
    "            threads_active = False\n",
    "\n",
    "        if conn.recv == 1:\n",
    "            print('Recieved collision')\n",
    "            robot.speedl((0,0,0,0,0,0),0.05,1)\n",
    "            robot.movel((home[0],home[1],home[2],home[3],home[4],home[5]),0.01,0.01)\n",
    "            threads_active = False\n",
    "            \n",
    "        time.sleep(0.01)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_control(connection,detector,camera_params,tag_size,conn):\n",
    "    global tag,tag_pose,threads_active\n",
    "    print(\"camera control process started\")\n",
    "    \n",
    "    while threads_active:\n",
    "        image_len = struct.unpack(\n",
    "            '<L', connection.read(struct.calcsize('<L')))[0]\n",
    "        # print('I am here')\n",
    "        if not image_len:\n",
    "            break\n",
    "        image_stream = io.BytesIO()\n",
    "        image_stream.write(connection.read(image_len))\n",
    "        image_stream.seek(0)\n",
    "        image = Image.open(image_stream)\n",
    "        opencvImage = cv2.cvtColor(numpy.array(image), cv2.COLOR_RGB2BGR)\n",
    "        gray = cv2.cvtColor(opencvImage, cv2.COLOR_BGR2GRAY)\n",
    "        result = detector.detect(\n",
    "            gray, estimate_tag_pose=True, camera_params=camera_params, tag_size=tag_size)\n",
    "\n",
    "        if result:\n",
    "            tag = True\n",
    "            tag_pose = result[0].pose_t\n",
    "            print('coords=',tag_pose)\n",
    "        else:\n",
    "            tag=False\n",
    "            tag_pose = []\n",
    "        cv2.imshow('Image', opencvImage)\n",
    "\n",
    "        if tag and np.linalg.norm(tag_pose) < 0.2:\n",
    "            conn.send(1)\n",
    "            print('COLLISION Sent')\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord('q'):\n",
    "            threads_active = False\n",
    "        time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_params = (506.19083684, 508.36108854,\n",
    "                 317.93111342, 243.12403806)\n",
    "tag_size = 0.0375\n",
    "\n",
    "UDP_IP = \"127.0.0.1\"\n",
    "UDP_PORT = 5065\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "server_socket = socket.socket()\n",
    "server_socket.bind(('0.0.0.0', 8000))\n",
    "server_socket.listen(0)\n",
    "connection = server_socket.accept()[0].makefile('rb')\n",
    "\n",
    "accuracy = 0.001\n",
    "\n",
    "detector = apriltag.Detector(\n",
    "    families='tag36h11',\n",
    "    nthreads=10,\n",
    "    quad_decimate=0.5,\n",
    "    quad_sigma=0,\n",
    "    refine_edges=1,\n",
    "    decode_sharpening=0.6,\n",
    "    debug=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob = urx.Robot('192.168.88.60')\n",
    "home = [-0.297,\n",
    " -0.142,\n",
    " 0.49,\n",
    " 0.11,\n",
    " -1.52,\n",
    " 0.19]\n",
    "goal = [-0.41,\n",
    " -0.142,\n",
    " 0.49,\n",
    " 0.11,\n",
    " -1.52,\n",
    " 0.19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.4130098640207345,\n",
       " -0.1422330594335932,\n",
       " 0.49061181924385733,\n",
       " 0.10995041598225339,\n",
       " -1.5199074785624982,\n",
       " 0.18999002588060435]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rob.getl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coord_reciever thread started\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coords= [[-0.00237117]\n",
      " [-0.01241012]\n",
      " [ 0.1918343 ]]\n",
      "COLLISION\n"
     ]
    }
   ],
   "source": [
    "threads_active=True\n",
    "conn1, conn2 = mp.Pipe()\n",
    "camera_control_process = mp.Process(\n",
    "target=camera_control,\n",
    "daemon=True,\n",
    "args=(connection,detector,camera_params,tag_size,conn2)\n",
    ")\n",
    "camera_control_process.start()\n",
    "\n",
    "manip_control_process = mp.Process(\n",
    "    target=manip_control,\n",
    "    daemon=True,\n",
    "    args=(rob,goal,home,accuracy,conn1)\n",
    ")\n",
    "manip_control_process.start()\n",
    "\n",
    "#let's see if it works\n",
    "manip_control_process.join()\n",
    "camera_control_process.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads_active=False\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Transform:\n",
       "<Orientation: \n",
       "array([[ 0.04013191, -0.19197181, -0.98057955],\n",
       "       [ 0.05520934,  0.98029698, -0.18965695],\n",
       "       [ 0.99766796, -0.04652586,  0.04993982]])>\n",
       "<Vector: (-0.40998, -0.14199, 0.49002)>\n",
       ">"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rob.movel(goal,0.05,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
